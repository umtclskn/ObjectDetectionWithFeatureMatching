{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitcarlaconda0e3a7f5a247e4e61b7b5120711bbf309",
   "display_name": "Python 3.7.9 64-bit ('carla': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#img1 = cv.imread('Small_area_rotated.png', cv.IMREAD_GRAYSCALE)\n",
    "img1 = cv.imread('Small_area.png', cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread('StarMap.png', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = cv.GaussianBlur(img1,(5,5),cv.BORDER_DEFAULT)\n",
    "img2 = cv.GaussianBlur(img2,(5,5),cv.BORDER_DEFAULT)\n",
    "\n",
    "sift = cv.SIFT_create(50000)\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "#-- Matching descriptor vectors with a FLANN based matcher\n",
    "matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "knn_matches = matcher.knnMatch(des1, des2, 2)\n",
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.8\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    "                   \n",
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv.drawMatches(img1, kp1, img2, kp2, good_matches, img_matches, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "#-- Show detected matches\n",
    "cv.imshow('Good Matches & Object detection', img_matches)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Localize the object\n",
    "obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "for i in range(len(good_matches)):\n",
    "    #-- Get the keypoints from the good matches\n",
    "    obj[i,0] = kp1[good_matches[i].queryIdx].pt[0]\n",
    "    obj[i,1] = kp1[good_matches[i].queryIdx].pt[1]\n",
    "    scene[i,0] = kp2[good_matches[i].trainIdx].pt[0]\n",
    "    scene[i,1] = kp2[good_matches[i].trainIdx].pt[1]\n",
    "H, _ =  cv.findHomography(obj, scene, cv.RANSAC)\n",
    "#-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "obj_corners[0,0,0] = 0\n",
    "obj_corners[0,0,1] = 0\n",
    "obj_corners[1,0,0] = img1.shape[1]\n",
    "obj_corners[1,0,1] = 0\n",
    "obj_corners[2,0,0] = img1.shape[1]\n",
    "obj_corners[2,0,1] = img1.shape[0]\n",
    "obj_corners[3,0,0] = 0\n",
    "obj_corners[3,0,1] = img1.shape[0]\n",
    "scene_corners = cv.perspectiveTransform(obj_corners, H)\n",
    "#-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "cv.line(img_matches, (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1])), (int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1])), (int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1])), (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1])), (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "\n",
    "\n",
    "cv.imwrite(\"result.png\",img_matches)\n",
    "\n",
    "#-- Show detected matches\n",
    "cv.imshow('Good Matches & Object detection', img_matches)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(969, 150), (1082, 150)]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "[ (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1])),  (int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(1082, 150), (1083, 263)]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "[(int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1])), (int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(1083, 263), (968, 264)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "[(int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1])), (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(968, 264), (969, 150)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "[ (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1])), (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(969, 150)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "(int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_points = [\n",
    "    (int(scene_corners[0,0,0]), int(scene_corners[0,0,1])),\n",
    "    (int(scene_corners[1,0,0]), int(scene_corners[1,0,1])),\n",
    "    (int(scene_corners[3,0,0]), int(scene_corners[3,0,1])),\n",
    "    (int(scene_corners[0,0,0]), int(scene_corners[0,0,1]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(855, 150), (968, 150), (854, 264), (855, 150)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "result_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Solution initialized...\n",
      "[(855, 150), (968, 150), (969, 263), (855, 264)]\n"
     ]
    }
   ],
   "source": [
    "from solution import Solution\n",
    "\n",
    "img1 = cv.imread('Small_area.png')\n",
    "img2 = cv.imread('StarMap.png')\n",
    "\n",
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "\n",
    "img1_copy = cv.cvtColor(img1, cv.COLOR_RGB2GRAY)\n",
    "img2_copy = cv.cvtColor(img2, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "solution = Solution()\n",
    "points = solution.localize_object(img1_copy, img2_copy)\n",
    "\n",
    "print(points)\n",
    "\n",
    "image_detected = np.copy(img2)\n",
    "\n",
    "cv.line(image_detected, points[0], points[1], (0,255,0), 4)\n",
    "cv.line(image_detected, points[1], points[2], (0,255,0), 4)\n",
    "cv.line(image_detected, points[2], points[3], (0,255,0), 4)\n",
    "cv.line(image_detected, points[3], points[0], (0,255,0), 4)\n",
    "\n",
    "\n",
    "#-- Show detected matches\n",
    "cv.imshow('Good Matches & Object detection', image_detected)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}